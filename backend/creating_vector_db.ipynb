{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='ft:gpt-3.5-turbo-0613:personal::8uxCCi0E', created=1708584608, object='model', owned_by='user-ytmkzl0r6xagbxpsxxaj5blz'), Model(id='ft:gpt-3.5-turbo-0613:personal:fathir-test:8v0dszJX', created=1708597857, object='model', owned_by='user-ytmkzl0r6xagbxpsxxaj5blz'), Model(id='ft:gpt-3.5-turbo-0613:personal:fathir-test:8v0ekm3d', created=1708597910, object='model', owned_by='user-ytmkzl0r6xagbxpsxxaj5blz'), Model(id='ft:gpt-3.5-turbo-0125:personal::97hVwAj0', created=1711622592, object='model', owned_by='user-ytmkzl0r6xagbxpsxxaj5blz')], object='list')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install pytesseract\n",
    "# %pip install unstructured-pytesseract\n",
    "# %pip install faiss-cpu\n",
    "from openai import OpenAI\n",
    "import os\n",
    "# Set up your OpenAI API key\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"open_ai_key\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai_api_key\n",
    ")\n",
    "    \n",
    "models = client.models.list()\n",
    "\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "import pytesseract\n",
    "from IPython import display\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pinecone import Pinecone\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from langchain.vectorstores import Pinecone as pine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"open_ai_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=\"D:/vera - Copy (2)/Samples/sample1.pdf\",\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    extract_image_block_output_dir=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize elements by type\n",
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    Categorize extracted elements from a PDF into tables and texts.\n",
    "    raw_pdf_elements: List of unstructured.documents.elements\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))\n",
    "    return texts, tables\n",
    "\n",
    "# Get text, tables\n",
    "texts, tables = categorize_elements(raw_pdf_elements)\n",
    "\n",
    "# Optional: Enforce a specific token size for texts\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=4000, chunk_overlap=0\n",
    ")\n",
    "joined_texts = \" \".join(texts)\n",
    "texts_4k_token = text_splitter.split_text(joined_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries of text elements\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Text summary chain\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\",api_key = openai_api_key)\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "# Get text, table summaries\n",
    "text_summaries, table_summaries = generate_text_summaries(\n",
    "    texts_4k_token, tables, summarize_texts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary of SriLankan Airlines Annual Report 2023/24**\\n\\n- **Overview**: SriLankan Airlines, the national carrier of Sri Lanka, aims to be the preferred airline for travelers seeking an authentic Sri Lankan experience. The report covers the financial year from April 1, 2023, to March 31, 2024.\\n\\n- **Vision & Mission**: The airline aspires to promote Sri Lanka globally, support tourism, and develop an air transport hub while maintaining ethical business practices.\\n\\n- **Financial Highlights**: \\n  - Group Revenue: LKR 339.6 billion\\n  - Group Operating Profit (before exchange gains): LKR 39.7 billion\\n  - Net Profit: LKR 7.9 billion\\n  - Passenger Revenue: LKR 276.2 billion; Cargo Revenue: LKR 31 billion (39% decrease).\\n\\n- **Operational Challenges**: The airline faced labor shortages, fleet constraints, and increased operational costs due to global supply chain issues. Over 1,000 flights were canceled, costing over USD 60 million.\\n\\n- **Strategic Initiatives**: \\n  - Wet leasing aircraft during peak seasons.\\n  - Enhancing global presence and partnerships.\\n  - Upgrading IT infrastructure and improving customer offerings.\\n\\n- **Sustainability Commitment**: The airline aims for net-zero carbon emissions by 2050, introducing eco-friendly initiatives and community engagement projects.\\n\\n- **Governance**: Strong governance framework ensuring accountability and transparency.\\n\\n- **Future Outlook**: Anticipates growth driven by tourism recovery and government support, including capital infusion to reduce debt.\\n\\n- **Key Awards**: Recognized for high-quality service, including awards for inflight catering and marketing excellence.\\n\\nThis summary encapsulates the key elements of the report, focusing on financial performance, operational challenges, strategic initiatives, and future outlook, optimized for retrieval.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image summaries\n",
    "image_elements = []\n",
    "image_summaries = []\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "def summarize_image(encoded_image):\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are financial analyst tasking with providing investment advice\"),\n",
    "        HumanMessage(content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are financial analyst tasking with providing investment advice.\\n\"\n",
    "            \"You will be given a mixed of text, tables, and image(s) usually of charts or graphs.\\n\"\n",
    "            \"Use this information to provide investment advice related to the user question. \\n\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ])\n",
    "    ]\n",
    "    response = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", openai_api_key=openai_api_key, max_tokens=1024).invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "for i in os.listdir(output_path):\n",
    "    if i.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(output_path, i)\n",
    "        encoded_image = encode_image(image_path)\n",
    "        image_elements.append(encoded_image)\n",
    "        summary = summarize_image(encoded_image)\n",
    "        image_summaries.append(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To provide investment advice regarding SriLankan Airlines, I would need specific data or context about the airline's current financial performance, market position, trends in the aviation industry, and any recent developments or challenges the airline is facing. Key factors to consider include:\\n\\n1. **Financial Performance**: Review revenue, profit margins, and operational costs. Look for trends in passenger numbers and cargo revenue.\\n\\n2. **Market Trends**: Analyze the travel demand, especially post-pandemic recovery, and how it impacts the airline industry.\\n\\n3. **Competitive Landscape**: Understand how SriLankan Airlines compares to competitors in terms of routes, pricing, and service quality.\\n\\n4. **Regulatory Environment**: Consider any government policies or regulations affecting the airline, especially in relation to international travel.\\n\\n5. **Strategic Initiatives**: Look into any strategic partnerships, fleet expansion plans, or sustainability initiatives.\\n\\n6. **Economic Indicators**: Assess broader economic factors such as fuel prices, currency fluctuations, and tourism trends in Sri Lanka.\\n\\nIf you can provide more detailed information or specific metrics, I can offer a more tailored investment analysis.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FAISS vectordb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Documents and Vectorstore\n",
    "documents = []\n",
    "retrieve_contents = []\n",
    "\n",
    "for e, s in zip(texts, text_summaries):\n",
    "    i = str(uuid.uuid4())\n",
    "    doc = Document(\n",
    "        page_content = s,\n",
    "        metadata = {\n",
    "            'id': i,\n",
    "            'type': 'text',\n",
    "            'original_content': e\n",
    "        }\n",
    "    )\n",
    "    retrieve_contents.append((i, e))\n",
    "    documents.append(doc)\n",
    "\n",
    "for e, s in zip(tables, table_summaries):\n",
    "    doc = Document(\n",
    "        page_content = s,\n",
    "        metadata = {\n",
    "            'id': i,\n",
    "            'type': 'table',\n",
    "            'original_content': e\n",
    "        }\n",
    "    )\n",
    "    retrieve_contents.append((i, e))\n",
    "    documents.append(doc)\n",
    "\n",
    "for e, s in zip(image_elements, image_summaries):\n",
    "    doc = Document(\n",
    "        page_content = s,\n",
    "        metadata = {\n",
    "            'id': i,\n",
    "            'type': 'image',\n",
    "            'original_content': e\n",
    "        }\n",
    "    )\n",
    "    retrieve_contents.append((i, s))\n",
    "    documents.append(doc)\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=documents, embedding=OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.docstore._dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As a single function - adding to existing database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_vectors_to_faiss(texts,text_summaries,tables,table_summaries,image_elements,image_summaries):\n",
    "    # Create Documents and Vectorstore\n",
    "    documents = []\n",
    "    retrieve_contents = []\n",
    "\n",
    "    for e, s in zip(texts, text_summaries):\n",
    "        i = str(uuid.uuid4())\n",
    "        doc = Document(\n",
    "            page_content = s,\n",
    "            metadata = {\n",
    "                'id': i,\n",
    "                'type': 'text',\n",
    "                'original_content': e\n",
    "            }\n",
    "        )\n",
    "        retrieve_contents.append((i, e))\n",
    "        documents.append(doc)\n",
    "\n",
    "    for e, s in zip(tables, table_summaries):\n",
    "        doc = Document(\n",
    "            page_content = s,\n",
    "            metadata = {\n",
    "                'id': i,\n",
    "                'type': 'table',\n",
    "                'original_content': e\n",
    "            }\n",
    "        )\n",
    "        retrieve_contents.append((i, e))\n",
    "        documents.append(doc)\n",
    "\n",
    "    for e, s in zip(image_elements, image_summaries):\n",
    "        doc = Document(\n",
    "            page_content = s,\n",
    "            metadata = {\n",
    "                'id': i,\n",
    "                'type': 'image',\n",
    "                'original_content': e\n",
    "            }\n",
    "        )\n",
    "        retrieve_contents.append((i, s))\n",
    "        documents.append(doc)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(documents=documents, embedding=OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "    vectorstore.save_local(\"faiss_index_new\")\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    db_new = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "    db = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "    db = db.merge_from(db_new)\n",
    "\n",
    "    return db   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PINECONE vector db**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=\"c5198c4f-c653-4860-a900-cd2e67f21ce3\")\n",
    "index = pc.Index(\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(\n",
    "    api_key= openai_api_key\n",
    ")\n",
    "MODEL = \"text-embedding-ada-002\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_and_upsert(texts):\n",
    "    batch_size = 10  # Adjust based on your rate limits and testing\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        # Generate embeddings for the batch\n",
    "        res = openai_client.embeddings.create(\n",
    "            input=batch_texts,\n",
    "            model=MODEL\n",
    "        )\n",
    "        embeddings = [np.array(record.embedding) for record in res.data]\n",
    "        \n",
    "        # Upsert embeddings to Pinecone with metadata\n",
    "        vectors = []\n",
    "        for text, embedding in zip(batch_texts, embeddings):\n",
    "            vectors.append({\n",
    "                \"id\": str(uuid.uuid4()),  # Generate a unique ID for each vector\n",
    "                \"values\": embedding.tolist(),  # Convert embedding to list\n",
    "                \"metadata\": {\"text\": text}  # Include original text as metadata\n",
    "            })\n",
    "        index.upsert(vectors=vectors)\n",
    "        \n",
    "# Combine all summaries into one list\n",
    "all_summaries = table_summaries + text_summaries + image_summaries\n",
    "\n",
    "generate_embeddings_and_upsert(all_summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
